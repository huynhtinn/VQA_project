
# ğŸ§  Generative VQA: End-to-End Visual Question Answering System

## ğŸŒŸ Overview

This repository presents a full **end-to-end Visual Question Answering (VQA)** pipeline, from dataset generation using **generative AI** to training a **custom deep learning model** that can answer natural-language questions about images of animals.

---

## âœ¨ Core Features

- ğŸ¤– **Automated Dataset Generation** using BLIP + Gemini APIs  
- ğŸ–¼ï¸ **Image Captioning** with BLIP  
- ğŸ“„ **Question-Answer Pair Generation** with Gemini API  
- ğŸ§  **Custom VQA Model**: CNN + LSTM + Attention + LSTM Decoder  
- ğŸ“ˆ **Training & Evaluation** with visual outputs and loss tracking  
- âš¡ **Colab-Ready**: Easy to run with GPU support

---

## ğŸ”„ Project Pipeline

### Stage 1: Automated Dataset Creation

```mermaid
graph LR
    A[Animal Image] --> B[BLIP Captioning]
    B --> C[Caption Text]
    C --> D[Gemini Q&A Generation]
    D --> E[Q&A JSON Dataset]
````

* **BLIP**: Generates captions for each image
* **Gemini API**: Uses captions to create question-answer pairs

---

### Stage 2: Model Training & Evaluation

* ğŸ“¥ **Input**: (Image, Question) â†’ ğŸ§  VQA Model â†’ ğŸ“¤ Answer
* ğŸ” Model Architecture:

  * **CNN**: Extract visual features
  * **LSTM (Q)**: Encode question
  * **Attention**: Align question with image features
  * **LSTM (Answer)**: Generate output tokens
* ğŸ§ª **Evaluation**: Visualize predictions & training loss

---

## ğŸš€ How to Run

1. **Open the notebook** in Colab
2. **Enable GPU**: Runtime â†’ Change Runtime Type â†’ GPU
3. **Mount Google Drive** for persistent storage
4. **Set paths** inside the notebook
5. **Run Cells**:

   * ğŸ”¸ Captioning (`generate_caption()`)
   * ğŸ”¸ Q\&A Generation (`get_gemini_qna_json()`)
   * ğŸ”¸ Model Training (`train_vqa()`)

> âš ï¸ You need a Gemini API Key:

```python
os.environ['GOOGLE_API_KEY'] = 'YOUR_API_KEY_HERE'
```

---

## ğŸ§ª Live Demo

Want to try it out? ğŸ‘‰ Click below to test the VQA model directly in your browser:

<p align="center">
  <a href="https://huggingface.co/spaces/Tin113/vqa_project">
    <img src="https://img.shields.io/badge/HuggingFace-%F0%9F%A4%97-yellow">
  </a>
</p>

Upload an animal image, ask a question, and get an answer from our VQA model â€” no installation required!


ğŸ§‘â€ğŸ« This project was developed for the **Deep Learning course** at **Ton Duc Thang University**.

